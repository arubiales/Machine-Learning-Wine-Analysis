{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification Model\n",
    "#### Predict the wine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, classification_report, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.7.4 64bit [GCC 7.3.0]"
        },
        {
         "module": "IPython",
         "version": "7.8.0"
        },
        {
         "module": "OS",
         "version": "Linux 5.0.0 27 generic x86_64 with debian buster sid"
        },
        {
         "module": "pandas",
         "version": "0.25.1"
        },
        {
         "module": "sklearn",
         "version": "0.21.2"
        },
        {
         "module": "matplotlib",
         "version": "3.1.1"
        },
        {
         "module": "xgboost",
         "version": "0.90"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.7.4 64bit [GCC 7.3.0]</td></tr><tr><td>IPython</td><td>7.8.0</td></tr><tr><td>OS</td><td>Linux 5.0.0 27 generic x86_64 with debian buster sid</td></tr><tr><td>pandas</td><td>0.25.1</td></tr><tr><td>sklearn</td><td>0.21.2</td></tr><tr><td>matplotlib</td><td>3.1.1</td></tr><tr><td>xgboost</td><td>0.90</td></tr><tr><td colspan='2'>Tue Sep 10 20:40:35 2019 CEST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.7.4 64bit [GCC 7.3.0] \\\\ \\hline\n",
       "IPython & 7.8.0 \\\\ \\hline\n",
       "OS & Linux 5.0.0 27 generic x86\\_64 with debian buster sid \\\\ \\hline\n",
       "pandas & 0.25.1 \\\\ \\hline\n",
       "sklearn & 0.21.2 \\\\ \\hline\n",
       "matplotlib & 3.1.1 \\\\ \\hline\n",
       "xgboost & 0.90 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Tue Sep 10 20:40:35 2019 CEST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.7.4 64bit [GCC 7.3.0]\n",
       "IPython 7.8.0\n",
       "OS Linux 5.0.0 27 generic x86_64 with debian buster sid\n",
       "pandas 0.25.1\n",
       "sklearn 0.21.2\n",
       "matplotlib 3.1.1\n",
       "xgboost 0.90\n",
       "Tue Sep 10 20:40:35 2019 CEST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%version_information pandas, sklearn, matplotlib, xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load and prepare de data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('Data/wine_train.pkl')\n",
    "test = pd.read_pickle('Data/wine_test.pkl')\n",
    "X_train = train.drop(columns=['color', 'quality'])\n",
    "y_train = train[['quality']]\n",
    "X_test = test.drop(columns=['color', 'quality'])\n",
    "y_test = test[['quality']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instance our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "lr = LogisticRegression()\n",
    "kn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "bg = BaggingClassifier()\n",
    "\n",
    "#our scaler too\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt = Pipeline(steps=[(\"scaler\", scaler), ('dt', dt)])\n",
    "pipeline_lr = Pipeline(steps=[('scaler', scaler), ('lr', lr)])\n",
    "pipeline_kn = Pipeline(steps=[('scaler', scaler), ('kn', kn)])\n",
    "pipeline_svc = Pipeline(steps=[('scaler', scaler), ('svc', svc)])\n",
    "pipeline_rf = Pipeline(steps=[('scaler', scaler), ('rf', rf)])\n",
    "pipeline_xgb = Pipeline(steps=[('scaler', scaler), ('xgb', xgb)])\n",
    "pipeline_bg = Pipeline(steps=[('scaler', scaler), ('bg', bg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt = {\"scaler__with_mean\": [True, False],\n",
    "           \"scaler__with_std\": [True, False],\n",
    "           \"dt__max_depth\": [2,3,4,5,6],\n",
    "           \"dt__min_samples_split\": [3,4,5,10],\n",
    "           \"dt__min_samples_leaf\": [3,4,5,10],\n",
    "           \"dt__class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "grid_lr = {\"scaler__with_mean\": [True, False],\n",
    "           \"scaler__with_std\": [True, False],\n",
    "           \"lr__C\": [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "           \"lr__fit_intercept\": [True, False],\n",
    "           \"lr__multi_class\": ['ovr', 'auto'],\n",
    "           \"lr__class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "grid_kn = {\"scaler__with_mean\": [True, False],\n",
    "            \"scaler__with_std\": [True, False],\n",
    "            \"kn__n_neighbors\": [1,3,5,7,9,11],\n",
    "            \"kn__metric\": [\"minkowski\", \"euclidean\"],\n",
    "            \"kn__p\": [1,2,3,4]}\n",
    "\n",
    "grid_svc = {\"scaler__with_std\": [True],\n",
    "            \"svc__C\": [0.1, 0.5, 1.0, 2.0],\n",
    "            \"svc__kernel\": [\"linear\", \"rbf\"],\n",
    "            \"svc__degree\": [2,3,4],\n",
    "            \"svc__class_weight\": [None, \"balanced\"],\n",
    "            \"svc__decision_function_shape\": ['ovo', 'ovr']}\n",
    "\n",
    "grid_rf = {\"scaler__with_mean\": [True, False],\n",
    "           \"scaler__with_std\": [True, False],\n",
    "           \"rf__n_estimators\": [10, 30, 50, 100, 150, 200],\n",
    "           \"rf__max_depth\": [3,4,5,6],\n",
    "           \"rf__min_samples_split\": [3,4,5,10],\n",
    "           \"rf__min_samples_leaf\": [3,4,5,10],\n",
    "           \"rf__class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "grid_xgb = {\"scaler__with_mean\": [True, False],\n",
    "            \"scaler__with_std\": [True, False],\n",
    "            \"xgb__learning_rate\": [0.1, 0.01],\n",
    "            \"xgb__gamma\" : [0.3, 0.5, 1,],\n",
    "            \"xgb__max_depth\": [4, 7],\n",
    "            \"xgb__n_estimators\": [100, 250, 500, 1000],\n",
    "            \"xgb__objective\": [\"multi:softmax\"],\n",
    "            \"xgb__num_class\": [10]}\n",
    "\n",
    "grid_bg = {\"scaler__with_mean\": [True, False],\n",
    "           \"scaler__with_std\": [True, False],\n",
    "           \"bg__base_estimator\":[lr],\n",
    "           \"bg__n_estimators\": [30, 50, 70], \n",
    "           \"bg__max_samples\": [0.2, 0.4, 0.6], \n",
    "           \"bg__max_features\": [1,2,3,4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grid Search instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scorer = make_scorer(f1_score, greater_is_better=True, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt = GridSearchCV(estimator=pipeline_dt,\n",
    "                     param_grid=grid_dt,\n",
    "                     scoring= my_scorer,\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=pipeline_lr,\n",
    "                     param_grid=grid_lr,\n",
    "                     scoring=my_scorer,\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "gs_kn = GridSearchCV(estimator=pipeline_kn,\n",
    "                      param_grid=grid_kn,\n",
    "                      scoring=my_scorer,\n",
    "                      cv=10,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "gs_svc = GridSearchCV(estimator=pipeline_svc,\n",
    "                      param_grid=grid_svc,\n",
    "                      scoring=my_scorer,\n",
    "                      cv=10,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipeline_rf,\n",
    "                     param_grid=grid_rf,\n",
    "                     scoring=my_scorer,\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "gs_xgb = GridSearchCV(estimator=pipeline_xgb,\n",
    "                     param_grid=grid_xgb,\n",
    "                     scoring=my_scorer,\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "gs_bg = GridSearchCV(estimator=pipeline_bg,\n",
    "                     param_grid=grid_bg,\n",
    "                     scoring=my_scorer,\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_models = {\"Decision Tree\": gs_dt,\n",
    "                 \"LR\": gs_lr,\n",
    "                 \"KN\": gs_kn,\n",
    "                 \"SVC\": gs_svc,\n",
    "                 \"Random Forest\": gs_rf,\n",
    "                 \"XGB\": gs_xgb,\n",
    "                 \"GB\": gs_bg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Grid Search of Decision Tree\n",
      "Model F1 score in train 0.5808093045795978\n",
      "Model F1 score in test 0.4824561403508772\n",
      "MODEL Decision Tree FINISHED\n",
      "Doing Grid Search of LR\n",
      "Model F1 score in train 0.5568209353040949\n",
      "Model F1 score in test 0.518796992481203\n",
      "MODEL LR FINISHED\n",
      "Doing Grid Search of KN\n",
      "Model F1 score in train 0.6268475890477344\n",
      "Model F1 score in test 0.5225563909774437\n",
      "MODEL KN FINISHED\n",
      "Doing Grid Search of SVC\n",
      "Model F1 score in train 0.6275745093288103\n",
      "Model F1 score in test 0.5375939849624061\n",
      "MODEL SVC FINISHED\n",
      "Doing Grid Search of Random Forest\n",
      "Model F1 score in train 0.6210322267991277\n",
      "Model F1 score in test 0.5213032581453634\n",
      "MODEL Random Forest FINISHED\n",
      "Doing Grid Search of XGB\n",
      "Model F1 score in train 0.9294887327356434\n",
      "Model F1 score in test 0.5300751879699248\n",
      "MODEL XGB FINISHED\n",
      "Doing Grid Search of GB\n",
      "Model F1 score in train 0.5255633632178338\n",
      "Model F1 score in test 0.4849624060150376\n",
      "MODEL GB FINISHED\n",
      "Time training model 38.0 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for name, gs in bag_of_models.items():\n",
    "    print(\"Doing Grid Search of {}\".format(name))\n",
    "    gs.fit(X_train, y_train)\n",
    "    model = gs.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    train_predict_f1 = f1_score(model.predict(X_train), y_train, average='micro')\n",
    "    print(\"Model F1 score in train {}\".format(train_predict_f1))\n",
    "    test_predict_f1 = f1_score(model.predict(X_test), y_test, average='micro')\n",
    "    print('Model F1 score in test {}'.format(test_predict_f1))\n",
    "    print(\"MODEL {} FINISHED\".format(name))\n",
    "end = time.time()\n",
    "print(\"Time training model {} min\".format(np.around((end - start)/60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Create groups: bad, regular, good\n",
    "we can see that the multiclassification have a week F1 score, lets try to do bigger groups and test the F1 score again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_group(quality):\n",
    "    if quality == 3 or quality == 4:\n",
    "        return 0 #bad wine\n",
    "    elif quality == 5 or quality == 6 or quality == 7:\n",
    "        return 1 #regular wine\n",
    "    else:\n",
    "        return 2 #good wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new_quality'] = train.apply(lambda x: quality_group(x['quality']), axis=1)\n",
    "test['new_quality'] = test.apply(lambda x: quality_group(x['quality']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = train.drop(columns=['color', 'quality', 'new_quality'])\n",
    "y_train2 = train[['new_quality']]\n",
    "X_test2 = test.drop(columns=['color', 'quality', 'new_quality'])\n",
    "y_test2 = test[['new_quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Grid Search of Decision Tree\n",
      "Model accuracy in train 0.9372425490671191\n",
      "Model accuracy in test 0.9085213032581454\n",
      "MODEL Decision Tree FINISHED\n",
      "Doing Grid Search of LR\n",
      "Model accuracy in train 0.9372425490671191\n",
      "Model accuracy in test 0.9085213032581454\n",
      "MODEL LR FINISHED\n",
      "Doing Grid Search of KN\n",
      "Model accuracy in train 0.9386963896292707\n",
      "Model accuracy in test 0.9060150375939849\n",
      "MODEL KN FINISHED\n",
      "Doing Grid Search of SVC\n",
      "Model accuracy in train 0.9372425490671191\n",
      "Model accuracy in test 0.9085213032581454\n",
      "MODEL SVC FINISHED\n",
      "Doing Grid Search of Random Forest\n",
      "Model accuracy in train 0.9379694693481948\n",
      "Model accuracy in test 0.9085213032581454\n",
      "MODEL Random Forest FINISHED\n",
      "Doing Grid Search of XGB\n",
      "Model accuracy in train 0.9430579113157257\n",
      "Model accuracy in test 0.9085213032581454\n",
      "MODEL XGB FINISHED\n",
      "Doing Grid Search of GB\n",
      "Model accuracy in train 0.9372425490671191\n",
      "Model accuracy in test 0.9085213032581454\n",
      "MODEL GB FINISHED\n",
      "Time training model 27.0 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for name, gs in bag_of_models.items():\n",
    "    print(\"Doing Grid Search of {}\".format(name))\n",
    "    gs.fit(X_train2, y_train2)\n",
    "    model = gs.best_estimator_\n",
    "    model.fit(X_train2, y_train2)\n",
    "    train_predict_f1 = f1_score(model.predict(X_train2), y_train2, average='micro')\n",
    "    print(\"Model accuracy in train {}\".format(train_predict_f1))\n",
    "    test_predict_f1 = f1_score(model.predict(X_test2), y_test2, average='micro')\n",
    "    print('Model accuracy in test {}'.format(test_predict_f1))\n",
    "    print(\"MODEL {} FINISHED\".format(name))\n",
    "end = time.time()\n",
    "print(\"Time training model {} min\".format(np.around((end - start)/60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the last notebooks, XGB is the model with best score in train, but the same in test, so to change we are going to pick the SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Interprete the model\n",
    "SVM is the only linear model which can classify data which is not linearly separable. The model multiply the feature by itself so many times as we fix in the \"degree\" hyperparameter, creating spaces with 2, 3, 4... dimensions in which the data is linearly separable. the problem is that this calculous is computationally very expensive, so we can't fix a degree 100, or do a grid search with a lot of differents degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovo', degree=2,\n",
       "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_models['SVC'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=2, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_champion = SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                     decision_function_shape='ovo', degree=2,\n",
    "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
    "                     probability=False, random_state=None, shrinking=True,\n",
    "                     tol=0.001, verbose=2)\n",
    "\n",
    "svc_champion.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score en Train:  0.9372425490671191\n",
      "F1 score en Test:  0.9085213032581454\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score en Train: \", f1_score(svc_champion.predict(X_train2), y_train2, average='micro'))\n",
    "print(\"F1 score en Test: \", f1_score(svc_champion.predict(X_test2), y_test2, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0],\n",
       "       [ 52, 725,  21],\n",
       "       [  0,   0,   0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svc_champion.predict(X_test2), y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0],\n",
       "       [ 137, 3868,  122],\n",
       "       [   0,    0,    0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svc_champion.predict(X_train2), y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a horrible model with a very good score. Our model is terrible, as we can see our dataset is very unbalanced and the model predicts all wines as \"regular\" wines, so it's not a predictive model.  \n",
    "Let's try with a balanced hyperparamenter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=2, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc2 = SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "                     decision_function_shape='ovo', degree=2,\n",
    "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
    "                     probability=False, random_state=None, shrinking=True,\n",
    "                     tol=0.001, verbose=2)\n",
    "svc2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  98, 1058,    7],\n",
       "       [  30, 1877,   23],\n",
       "       [   9,  933,   92]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svc2.predict(X_train2), y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cofusion Matrix looks very bad, we're going to try to make other groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_group(quality):\n",
    "    if quality == 3 or quality == 4 or quality == 5:\n",
    "        return 0 #bad wine\n",
    "    elif quality == 6:\n",
    "        return 1 #regular wine\n",
    "    else:\n",
    "        return 2 #good wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new_quality'] = train.apply(lambda x: quality_group(x['quality']), axis=1)\n",
    "test['new_quality'] = test.apply(lambda x: quality_group(x['quality']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = train.drop(columns=['color', 'quality', 'new_quality'])\n",
    "y_train2 = train[['new_quality']]\n",
    "X_test2 = test.drop(columns=['color', 'quality', 'new_quality'])\n",
    "y_test2 = test[['new_quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_quality\n",
       "0    1491\n",
       "1    1832\n",
       "2     804\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['new_quality'])['quality'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is not completly balanced but looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=2, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc3 = SVC(C=0.1, cache_size=200, coef0=0.0,\n",
    "                     decision_function_shape='ovo', degree=2,\n",
    "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
    "                     probability=False, random_state=None, shrinking=True,\n",
    "                     tol=0.001, verbose=2)\n",
    "svc3.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 988,  460,   48],\n",
       "       [ 503, 1372,  756],\n",
       "       [   0,    0,    0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svc3.predict(X_train2), y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrible results, too. So in this point we can't create a good multiclass model, we can try some things to improve our model.\n",
    "\n",
    "1. Collect more data \n",
    "2. Make a better preprocessing \n",
    "3. Try other complex techniques to create synthetic data\n",
    "4. If we only want to predict the class and don't care about the explanation of the model, we can make a Neural Network\n",
    "\n",
    "We will not explain the output variables of this model because it will have no sense with the real world\n",
    "\n",
    "PD: obviously is a very bad model so i will not save it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
